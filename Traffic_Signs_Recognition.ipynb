{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Basic notebook setup and utilities.\n",
    "\n",
    "\n",
    "# Whether to run functions that demonstrate parts of the project.\n",
    "__demos__ = True\n",
    "\n",
    "\n",
    "class Attributes(object):\n",
    "    r'''Dynamic collection of named attributes.\n",
    "    '''\n",
    "    def __setattr__(self, name, value):\n",
    "        object.__setattr__(self, name, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Exploration\n",
    "\n",
    "Visualize the German Traffic Signs Dataset. This is open ended, some suggestions include: plotting traffic signs images, plotting the count of each sign, etc. Be creative!\n",
    "\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- features -> the images pixel values, (width, height, channels)\n",
    "- labels -> the label of the traffic sign\n",
    "- sizes -> the original width and height of the image, (width, height)\n",
    "- coords -> coordinates of a bounding box around the sign in the image, (x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Basic dataset manipulation classes.\n",
    "\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from glob import iglob\n",
    "from os.path import isdir\n",
    "from os.path import join as join_path\n",
    "from re import search\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "\n",
    "\n",
    "class Data(object):\n",
    "    r'''Base class for single-type data collection classes.\n",
    "    '''\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def extend(self, data):\n",
    "        self.data = np.concatenate([self.data, data])\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "\n",
    "class Images(Data):\n",
    "    r'''Collection of RGB images, represented as 3D arrays of unsigned 8-bit integers.\n",
    "    '''\n",
    "    def __init__(self, data):\n",
    "        Data.__init__(self, data)\n",
    "    \n",
    "    def image(self, index):\n",
    "        return self[index]\n",
    "    \n",
    "    \n",
    "class Labels(Data):\n",
    "    r'''Collection of class labels, represented as integer values.\n",
    "    '''\n",
    "    def __init__(self, data, breadth):\n",
    "        Data.__init__(self, data)\n",
    "        self.breadth = breadth\n",
    "        if breadth == None:\n",
    "            n = range(len(self))\n",
    "            classes = set(self.classof(i) for i in n)\n",
    "            self.breadth = len(classes)\n",
    "\n",
    "    def classof(self, index):\n",
    "        return self[index]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        classes = dict((c, []) for c in range(self.breadth))\n",
    "        for i in range(len(self)):\n",
    "            k = self.classof(i)\n",
    "            classes[k].append(i)\n",
    "        \n",
    "        return classes\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    r'''A collection of data cases and associated class identifiers.\n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        r'''Create a new dataset instance.\n",
    "        \n",
    "            Datasets can be loaded from files, for example:\n",
    "        \n",
    "                dataset = Dataset('title', 'path/to/pickled_file.p')\n",
    "            \n",
    "            They can also be created from other datasets:\n",
    "            \n",
    "                dataset = Dataset(other_dataset)\n",
    "            \n",
    "            or\n",
    "            \n",
    "                dataset = Dataset(title, X, y)\n",
    "        '''\n",
    "        if len(args) == 1:\n",
    "            self.__assign(args[0])\n",
    "            return\n",
    "        \n",
    "        self.title = args[0]\n",
    "        if len(args) == 2:\n",
    "            (X, y) = self.__load(args[1])\n",
    "            self.X = Images(X)\n",
    "            self.y = Labels(y, kwargs.get('breadth'))\n",
    "        elif len(args) == 3:\n",
    "            self.X = args[1]\n",
    "            self.y = args[2]\n",
    "        else:\n",
    "            raise Exception('Invalid argument list: %s' % str(args))\n",
    "\n",
    "    def __assign(self, dataset):\n",
    "        self.title = dataset.title\n",
    "        self.X = dataset.X\n",
    "        self.y = dataset.y\n",
    "\n",
    "    def __load(self, path):\n",
    "        if isdir(path):\n",
    "            X = []\n",
    "            y = []\n",
    "            for filename in iglob(join_path(path, '*')):\n",
    "                match = search(r'(\\d+)_\\d+\\.', filename)\n",
    "                if match != None:\n",
    "                    image = imread(filename)\n",
    "                    label = int(match.group(1))\n",
    "                    X.append(image)\n",
    "                    y.append(label)\n",
    "            \n",
    "            return (np.array(X), np.array(y))\n",
    "        \n",
    "        with open(path, mode='rb') as data:\n",
    "            dataset = pickle.load(data)\n",
    "            return (dataset['features'], dataset['labels'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __str__(self):\n",
    "        template = (\n",
    "            '%s dataset\\n'\n",
    "            'Number of entries: %d\\n'\n",
    "            'Input shape: %s\\n'\n",
    "            'Output shape: %s\\n'\n",
    "            'Number of classes: %d\\n'\n",
    "        )\n",
    "        \n",
    "        return template % (\n",
    "            self.title,\n",
    "            len(self),\n",
    "            str(self.X.shape[1:]),\n",
    "            str(self.y.shape[1:]),\n",
    "            self.y.breadth\n",
    "        )\n",
    "\n",
    "\n",
    "def Parameters():\n",
    "    r'''Create a new set of parameters for a neural network training problem.\n",
    "    '''\n",
    "    parameters = Attributes()\n",
    "    parameters.inputs = Attributes()\n",
    "    parameters.output = Attributes()\n",
    "    parameters.patch = Attributes()\n",
    "    parameters.batch = Attributes()\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def load_datasets():\n",
    "    data = Attributes()\n",
    "    data.train = Dataset('Train', 'datasets/pickled/train.p')\n",
    "    data.test = Dataset('Test', 'datasets/pickled/test.p', breadth=data.train.y.breadth)\n",
    "    return data\n",
    "\n",
    "\n",
    "def print_datasets(data):\n",
    "    for dataset in vars(data).values():\n",
    "        print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### To start off let's do a basic data summary.\n",
    "if __demos__ == True:\n",
    "    print_datasets(load_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Data visualization facilities.\n",
    "\n",
    "import csv\n",
    "from random import sample\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "# Widen the page region used for plots\n",
    "plt.rcParams['figure.figsize'] = (9.0, 4.0) # Otiginal: (6.0, 4.0)\n",
    "\n",
    "\n",
    "class Displayer(object):\n",
    "    def __init__(self, path):\n",
    "        with open(path) as csv_file:\n",
    "            csv_data = csv.reader(csv_file)\n",
    "            next(csv_data) # Discard column title row\n",
    "            self.labels = dict((int(row[0]), str(row[1])) for row in csv_data)\n",
    "\n",
    "    def __call__(self, dataset, width=5):\n",
    "        r'''Display `k` samples of each class from the given dataset.\n",
    "        '''\n",
    "        n = len(dataset)\n",
    "\n",
    "        print('\\n\\n  %s' % ('-' * 80))\n",
    "        print('  %s dataset (total %d entries)' % (dataset.title, n))\n",
    "        print('  %s\\n\\n' % ('-' * 80))\n",
    "\n",
    "        labels = self.labels\n",
    "        classes = dataset.y.classes\n",
    "\n",
    "        for c in range(len(classes)):\n",
    "            indexes = classes[c]\n",
    "            n = len(indexes)\n",
    "            if n == 0:\n",
    "                continue\n",
    "            \n",
    "            print('  Class %d (\"%s\", total %d entries) samples:' % (c, labels[c], len(indexes)))\n",
    "            k = min(width, n)\n",
    "            s = sample(indexes, k)\n",
    "            self.display_signs(dataset, s, width)\n",
    "\n",
    "    def display_signs(self, dataset, indexes, width):\n",
    "        r'''Display the indexed sign images and corresponding labels side by side.\n",
    "        '''\n",
    "        n = len(indexes)\n",
    "        for i in range(n):\n",
    "            plotter = plt.subplot2grid((1, width), (0, i))\n",
    "            self.display_sign(plotter, dataset, indexes[i])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def display_sign(self, plotter, dataset, i):\n",
    "        r'''Display a sign image and corresponding numeric label.\n",
    "        '''\n",
    "        plotter.imshow(dataset.X.image(i))\n",
    "        plotter.xaxis.set_visible(False)\n",
    "        plotter.yaxis.set_visible(False)\n",
    "        plotter.title.set_text(str(i))\n",
    "\n",
    "\n",
    "display = Displayer('datasets/signnames.csv')\n",
    "\n",
    "\n",
    "def display_datasets(data):\n",
    "    display(data.train)\n",
    "    display(data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Display summary statistics and samples for the training and test datasets.\n",
    "if __demos__ == True:\n",
    "    display_datasets(load_datasets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Your model can be derived from a deep feedforward net or a deep convolutional network.\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Data preprocessing facilities.\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "class Tensors(Images):\n",
    "    r'''Collection of multi-dimensional vectors.\n",
    "    '''\n",
    "    def __init__(self, values):\n",
    "        Images.__init__(self, values.astype(np.float32))\n",
    "    \n",
    "    def image(self, index):\n",
    "        x = self[index]\n",
    "        image = np.zeros(x.shape, dtype=np.uint8)\n",
    "        for d in range(3):\n",
    "            channel = np.array(x[:, :, d])\n",
    "            channel -= channel.min()\n",
    "            channel *= (255.0 / channel.max())\n",
    "            image[:, :, d] = channel.astype(np.uint8)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    \n",
    "class Likelihoods(Labels):\n",
    "    r'''Collection of vectors indicating the likelihoods an input belongs to each of a set of classes.\n",
    "    '''\n",
    "    def __init__(self, data, breadth):\n",
    "        Labels.__init__(self, data, breadth)\n",
    "        if len(data.shape) == 1:\n",
    "            self.data = (np.arange(self.breadth) == data[:, None]).astype(np.float32)\n",
    "\n",
    "    def classof(self, index):\n",
    "        return np.argmax(self[index])\n",
    "\n",
    "    \n",
    "class Vectorized(Dataset):\n",
    "    r'''A dataset where both inputs and outputs are represented as floating-point arrays.\n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        Dataset.__init__(self, *args, **kwargs)\n",
    "        self.X = Tensors(self.X.data)\n",
    "        self.y = Likelihoods(self.y.data, self.y.breadth)\n",
    "\n",
    "\n",
    "class Normalized(Dataset):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        Dataset.__init__(self, *args, **kwargs)\n",
    "\n",
    "        X = self.X\n",
    "        n = X.shape[0]\n",
    "        d = X.shape[-1]\n",
    "        for (i, j) in product(range(n), range(d)):\n",
    "            channel = X[i, :, :, j]\n",
    "            channel -= channel.mean()\n",
    "            channel /= channel.std()\n",
    "\n",
    "\n",
    "def load_vectorized():\n",
    "    data = load_datasets()\n",
    "    data.train = Vectorized(data.train)\n",
    "    data.test = Vectorized(data.test)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_normalized():\n",
    "    data = load_vectorized()\n",
    "    data.train = Normalized(data.train)\n",
    "    data.test = Normalized(data.test)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess training and test datasets.\n",
    "if __demos__ == True:\n",
    "    print_datasets(load_normalized())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe the techniques used to preprocess the data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "In order to ensure numeric stability and make the associated optimizaton problem well-conditioned [[^](https://www.youtube.com/watch?v=0mxNQA95mYE)], inputs are normalized to zero mean and unit standard deviation. This is done simply by converting images to floating-point multidimensional arrays and then normalizing each channel separately. Outputs are also preprocessed here, converted from integer label indicators to one hot-encoded vectors, for use later on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Separate a validation subset from the training dataset.\n",
    "\n",
    "from random import choice, triangular, shuffle\n",
    "\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "def jiggle(image, **kwargs):\n",
    "    r'''Perform slight changes to the input array.\n",
    "    \n",
    "        Input images are randomly multiplied by a brightness mask,\n",
    "        rolled around the horizontal and vertical axes, and rotated.\n",
    "    '''\n",
    "    r_dist = kwargs.get('r_dist', 5)\n",
    "    r_degs = kwargs.get('r_degs', 5)\n",
    "    r_scale = kwargs.get('r_scale', 0.1)\n",
    "    \n",
    "    tx = int(triangular(-r_dist, r_dist))\n",
    "    ty = int(triangular(-r_dist, r_dist))\n",
    "    sl = triangular(1.0 - r_scale, 1.0 + r_scale)\n",
    "    \n",
    "    r_rads = np.pi * r_degs / 180.0\n",
    "    t_rotate = triangular(-r_rads, r_rads)\n",
    "    t_shear = triangular(-r_rads, r_rads)\n",
    "\n",
    "    shear = AffineTransform(\n",
    "        rotation=t_rotate,\n",
    "        shear=t_shear,\n",
    "        translation=(tx, ty),\n",
    "        scale=(sl, sl)\n",
    "    )\n",
    "\n",
    "    return warp(image, shear, mode='wrap')\n",
    "\n",
    "\n",
    "def padding(dataset, **kwargs):\n",
    "    r'''Generate a dataset with randomly modified data items from the source dataset.\n",
    "    \n",
    "        Items are generated in inverse class distribution relative to the source dataset,\n",
    "        so that no items are generated for the most numerous class, and the least numerous\n",
    "        is given the most items.\n",
    "    '''\n",
    "    classes = dataset.y.classes.values()\n",
    "    X = dataset.X\n",
    "    y = dataset.y\n",
    "\n",
    "    n_class = kwargs.get('n_class')\n",
    "    if n_class == None:\n",
    "        n_class = np.max([len(cases) for cases in classes])\n",
    "\n",
    "    Xp = []\n",
    "    yp = []\n",
    "    for cases in classes:\n",
    "        n = len(cases)\n",
    "\n",
    "        if kwargs.get('all_jiggled') == True:\n",
    "            n = 0\n",
    "        else:\n",
    "            k = (sample(cases, n_class) if n_class <= n else cases)\n",
    "            Xp.extend(X[k])\n",
    "            yp.extend(y[k])\n",
    "\n",
    "        for i in range(n_class - n):\n",
    "            k = choice(cases)\n",
    "            Xp.append(jiggle(X[k], **kwargs))\n",
    "            yp.append(y[k])\n",
    "\n",
    "    DataX = X.__class__\n",
    "    DataY = y.__class__\n",
    "    breadth = dataset.y.breadth\n",
    "    \n",
    "    return Dataset('Padding', DataX(np.array(Xp)), DataY(np.array(yp), breadth))\n",
    "\n",
    "\n",
    "class Padded(Dataset):\n",
    "    r'''A dataset where all classes are guaranteed to have the same case count.\n",
    "    \n",
    "        If some classes in the original dataset contain more cases than others,\n",
    "        extra cases are generated through random transformations, until all\n",
    "        classes have the same number of cases.\n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        Dataset.__init__(self, *args, **kwargs)\n",
    "        dataset = padding(self, **kwargs)\n",
    "        self.X = dataset.X\n",
    "        self.y = dataset.y\n",
    "\n",
    "\n",
    "def split(dataset, rate=0.25):\n",
    "    X = dataset.X\n",
    "    y = dataset.y\n",
    "    \n",
    "    DataX = X.__class__\n",
    "    DataY = y.__class__\n",
    "\n",
    "    (X_train, X_valid, y_train, y_valid) = train_test_split(\n",
    "        X.data,\n",
    "        y.data,\n",
    "        test_size=rate,\n",
    "        random_state=832289\n",
    "    )\n",
    "    \n",
    "    breadth = dataset.y.breadth\n",
    "    return (\n",
    "        Dataset('Train', DataX(X_train), DataY(y_train, breadth)),\n",
    "        Dataset('Validate', DataX(X_valid), DataY(y_valid, breadth))\n",
    "    )\n",
    "\n",
    "\n",
    "def split_train(data):\n",
    "    (data.train, data.valid) = split(data.train)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __demos__ == True:\n",
    "    print_datasets(split_train(load_datasets()))\n",
    "    display(padding(load_datasets().train, all_jiggled=True, n_class=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Traffic signs are not equally represented in the training data set, with some appearing much more often than others. Such imbalance would make training statistics less reliable; this issue is addressed here through the generation of _jiggled_ duplicates of sign images from the less frequent classes. Jiggling involves rotating, translating and changing the brightness of images by random amounts within a restricted range. Once the classes are padded to the same size by the addition of jiggled images, a validation set is separated from the training set by randomly setting aside 30% of training cases. Both training and validation datasets are then shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def weights(*shape):\n",
    "    return tf.Variable(tf.truncated_normal(list(shape), stddev=0.1))\n",
    "\n",
    "\n",
    "def bias(b, n):\n",
    "    return tf.Variable(tf.constant(b, shape=[n]))\n",
    "\n",
    "\n",
    "def layer_depth(layer):\n",
    "    return layer.get_shape().as_list()[-1]\n",
    "\n",
    "\n",
    "def layer_2d(layer):\n",
    "    shape = layer.get_shape()\n",
    "    shape = [-1, shape[1:].num_elements()]\n",
    "    return tf.reshape(layer, shape)\n",
    "\n",
    "\n",
    "def layer_nl(layer):\n",
    "    return tf.nn.relu(layer)\n",
    "\n",
    "\n",
    "def layer_connected(layer, b, n):\n",
    "    m = layer_depth(layer)\n",
    "    return tf.matmul(layer, weights(m, n)) + bias(b, n)\n",
    "\n",
    "\n",
    "def layer_convolved(layer, side, depth, stride=1, padding='SAME', b=None):\n",
    "    strides = [1, stride, stride, 1]\n",
    "    W = weights(side, side, layer_depth(layer), depth)\n",
    "    C = tf.nn.conv2d(layer, W, strides, padding)\n",
    "    B = weights(depth) if b == None else bias(b, depth)\n",
    "    return C + B\n",
    "\n",
    "\n",
    "def layer_max_pool(layer, ksize, stride=None, padding='SAME'):\n",
    "    if stride == None:\n",
    "        stride = ksize\n",
    "    \n",
    "    return tf.nn.max_pool(layer, [1, ksize, ksize, 1], [1, stride, stride, 1], padding)\n",
    "\n",
    "\n",
    "# Architecture and parameters taken from:\n",
    "# https://hackathonprojects.wordpress.com/2016/09/25/inception-modules-explained-and-implemented/\n",
    "def inception_module(inputs, depth_1x1, depth_out, stride=1):\n",
    "    def conv_1x1(layer=inputs, depth=depth_out, stride=stride):\n",
    "        return layer_convolved(layer, 1, depth, stride)\n",
    "    \n",
    "    def conv_3x3():\n",
    "        reduced = layer_nl(conv_1x1(inputs, depth_1x1, 1))\n",
    "        return layer_convolved(reduced, 3, depth_out, stride)\n",
    "    \n",
    "    def conv_5x5():\n",
    "        reduced = layer_nl(conv_1x1(inputs, depth_1x1, 1))\n",
    "        return layer_convolved(reduced, 5, depth_out, stride)\n",
    "    \n",
    "    def max_pool():\n",
    "        pooled = tf.nn.max_pool(inputs, [1, 3, 3, 1], [1, 1, 1, 1], 'SAME')\n",
    "        return conv_1x1(pooled, depth_out)\n",
    "\n",
    "    return layer_nl(tf.concat(3, [conv_1x1(), conv_3x3(), conv_5x5(), max_pool()]))\n",
    "\n",
    "\n",
    "def mnist_architecture(inputs, parameters):\n",
    "    side = parameters.patch.side\n",
    "    depth = parameters.patch.depth\n",
    "    stride = parameters.stride\n",
    "    n_hidden = parameters.hidden_nodes\n",
    "    n_classes = parameters.output.classes\n",
    "\n",
    "    layer = layer_convolved(inputs, side, depth, stride, padding='VALID')\n",
    "    layer = layer_convolved(layer_nl(layer), side, depth, stride, padding='VALID')\n",
    "    layer = layer_nl(layer)\n",
    "\n",
    "    layer = layer_connected(layer_2d(layer), 1.0, n_hidden)\n",
    "    layer = layer_connected(layer_nl(layer), 1.0, n_classes)\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def mnist_architecture_2(inputs, parameters):\n",
    "    side = parameters.patch.side\n",
    "    depth = parameters.patch.depth\n",
    "    stride = parameters.stride\n",
    "    n_hidden = parameters.hidden_nodes\n",
    "    n_classes = parameters.output.classes\n",
    "\n",
    "    layer = layer_max_pool(inputs, stride)\n",
    "    layer = layer_convolved(layer, side, depth)\n",
    "    layer = layer_nl(layer)\n",
    "    layer = layer_max_pool(layer, stride)\n",
    "    layer = layer_convolved(layer, side, depth)\n",
    "    layer = layer_nl(layer)\n",
    "\n",
    "    layer = layer_connected(layer_2d(layer), 1.0, n_hidden)\n",
    "    layer = layer_connected(layer_nl(layer), 1.0, n_classes)\n",
    "\n",
    "    return layer\n",
    "    \n",
    "\n",
    "def mini_inception_architecture(inputs, parameters):\n",
    "    depth = parameters.patch.depth\n",
    "    stride = parameters.stride\n",
    "    n_hidden = parameters.hidden_nodes\n",
    "    n_classes = parameters.output.classes\n",
    "\n",
    "    def mini_inception_module(layer):\n",
    "        conv_1x1 = layer_convolved(layer, 1, depth, stride)\n",
    "        conv_3x3 = layer_convolved(layer, 3, depth, stride)\n",
    "        conv_5x5 = layer_convolved(layer, 5, depth, stride)\n",
    "        max_pool = layer_max_pool(layer, 3, stride)\n",
    "\n",
    "        inception = layer_nl(tf.concat(3, [conv_1x1, conv_3x3, conv_5x5, max_pool]))\n",
    "        return layer_nl(layer_convolved(inception, 1, depth))\n",
    "\n",
    "    layer = mini_inception_module(inputs)\n",
    "    layer = mini_inception_module(layer)\n",
    "\n",
    "    layer = layer_connected(layer_2d(layer), 1.0, n_hidden)\n",
    "    layer = layer_connected(layer_nl(layer), 1.0, n_classes)\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def inception_architecture(inputs, parameters):\n",
    "    depth = parameters.patch.depth\n",
    "    stride = parameters.stride\n",
    "    n_hidden = parameters.hidden_nodes\n",
    "    n_classes = parameters.output.classes\n",
    "\n",
    "    layer = inception_module(inputs, depth // 2, depth, stride)\n",
    "    layer = inception_module(layer, depth // 2, depth, stride)\n",
    "\n",
    "    layer = layer_connected(layer_2d(layer), 1.0, n_hidden)\n",
    "    layer = layer_connected(layer_nl(layer), 1.0, n_classes)\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "    def __init__(self, architecture, parameters):\n",
    "        l_input = parameters.inputs.side\n",
    "        d_input = parameters.inputs.depth\n",
    "        l_patch = parameters.patch.side\n",
    "        d_patch = parameters.patch.depth\n",
    "        n_hidden = parameters.hidden_nodes\n",
    "        n_classes = parameters.output.classes\n",
    "        \n",
    "        with tf.Graph().as_default(): # ensures variable names are consistent across network instances\n",
    "            self.inputs = tf.placeholder(tf.float32, shape=(None, l_input, l_input, d_input))\n",
    "            \n",
    "            outputs = architecture(self.inputs, parameters)\n",
    "\n",
    "            self.outputs = outputs\n",
    "            self.argmax = tf.argmax(outputs, 1)\n",
    "            self.session = tf.Session()\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.session.run(self.argmax, feed_dict={self.inputs: X})\n",
    "    \n",
    "    def init_variables(self):\n",
    "        with self.session.graph.as_default():\n",
    "            init = tf.initialize_all_variables()\n",
    "            self.session.run(init)            \n",
    "\n",
    "    \n",
    "def default_parameters():\n",
    "    parameters = Parameters()\n",
    "    parameters.stride = 1 # 2\n",
    "    parameters.inputs.side = 32\n",
    "    parameters.inputs.depth = 3\n",
    "    parameters.output.classes = 43\n",
    "    parameters.patch.side = 5\n",
    "    parameters.patch.depth = 32\n",
    "    parameters.hidden_nodes = 64\n",
    "    parameters.batch.size = 50\n",
    "    parameters.batch.step = 10\n",
    "    parameters.learning_rate = 0.1\n",
    "    #parameters.learning_rate = 1e-2\n",
    "    parameters.epochs = 5\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def default_network():\n",
    "    return Network(mnist_architecture, default_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __demos__ == True:\n",
    "    network = default_network()\n",
    "    print(repr(network.session.graph.as_graph_def()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)  For reference on how to build a deep neural network using TensorFlow, see [Deep Neural Network in TensorFlow\n",
    "](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/b516a270-8600-4f93-a0a3-20dfeabe5da6/concepts/83a3a2a2-a9bd-4b7b-95b0-eb924ab14432) from the classroom._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "After experimenting with several possibilities, I settled for what I call a _mini inception_ architecture. This is a convolutional network where inception modules (themselves composed of parallel 1x1, 3x3 and 5x5 convolutions and a max pool layer) are followed by 1x1 convolution layers, which reduce output dimensionality. This model showed a good balance between classification performance and training time. The sequence of mini inception modules is followed by a fully connected network with a single hidden layer, which uses the features extracted by the convolutional network for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "from math import ceil, floor\n",
    "from sys import maxsize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def batches(dataset, l, counter=range):\n",
    "    X = dataset.X\n",
    "    y = dataset.y\n",
    "    n = int(ceil(len(X) / l)) # Ensures a final \"rest\" batch will be issued as appropriate\n",
    "    for k in counter(n):\n",
    "        a = k * l\n",
    "        b = a + l\n",
    "        yield (k, X[a:b], y[a:b])\n",
    "\n",
    "\n",
    "class Accuracy(object):\n",
    "    def __init__(self, network, batch_size, *datasets):\n",
    "        self.inputs = network.inputs\n",
    "        self.session = network.session\n",
    "        with network.session.graph.as_default():\n",
    "            self.outputs = tf.placeholder(tf.float32)\n",
    "            is_correct_prediction = tf.equal(network.argmax, tf.argmax(self.outputs, 1))\n",
    "            self.accuracy = tf.reduce_sum(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "        self.datasets = datasets\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __call__(self):\n",
    "        def accuracy(dataset):\n",
    "            total = 0.0\n",
    "            count = 0.0\n",
    "            for (k, X_k, y_k) in batches(dataset, self.batch_size):\n",
    "                data = {self.inputs: X_k, self.outputs: y_k}\n",
    "                total += self.session.run(self.accuracy, feed_dict=data)\n",
    "                count += len(X_k)\n",
    "\n",
    "            return total / count\n",
    "\n",
    "        return tuple(accuracy(dataset) for dataset in self.datasets)\n",
    "\n",
    "\n",
    "class Optimizer(object):\n",
    "    def __init__(self, network, learning_rate):\n",
    "        self.inputs = network.inputs\n",
    "        self.session = network.session\n",
    "        with self.session.graph.as_default():\n",
    "            self.outputs = tf.placeholder(tf.float32)\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(network.outputs, self.outputs)\n",
    "            self.loss = tf.reduce_mean(cross_entropy)\n",
    "            # TODO: try different optimizer\n",
    "            # https://www.tensorflow.org/versions/r0.11/api_docs/python/train.html#AdamOptimizer\n",
    "            self.optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.loss)\n",
    "            #self.optimizer = tf.train.AdamOptimizer(1e-2, beta1=0.99, epsilon=0.1).minimize(self.loss)\n",
    "            \n",
    "    def __call__(self, X, y):\n",
    "        data = {self.inputs: X, self.outputs: y}\n",
    "        (_, l) = self.session.run([self.optimizer, self.loss], feed_dict=data)\n",
    "        return l\n",
    "\n",
    "\n",
    "def plot_lines(title, x, *ys, **kwargs):\n",
    "    y_min = maxsize\n",
    "    y_max = -maxsize\n",
    "\n",
    "    plotter = plt.subplot(111)\n",
    "    for (y, c, l) in ys:\n",
    "        label = '%s (last: %.3f)' % (l, round(y[-1], 3))\n",
    "        plotter.plot(x, y, c, label=label)\n",
    "        y_min = min(floor(np.min(y)), y_min)\n",
    "        y_max = max(ceil(np.max(y)), y_max)\n",
    "\n",
    "    plotter.set_title(title)\n",
    "    plotter.set_xlim([x[0], x[-1]])\n",
    "    plotter.set_ylim([y_min, y_max])\n",
    "    plotter.legend(loc=kwargs.get('loc', 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(network, data, parameters):\n",
    "    batch_size = parameters.batch.size\n",
    "    batch_step = parameters.batch.step\n",
    "    learning_rate = parameters.learning_rate\n",
    "    epochs = parameters.epochs\n",
    "\n",
    "    accuracy = Accuracy(network, parameters.batch.size, data.train, data.valid)\n",
    "    optimizer = Optimizer(network, learning_rate)\n",
    "    session = network.session\n",
    "\n",
    "    x_batch = []\n",
    "    y_train = []\n",
    "    y_valid = []\n",
    "    y_loss = []\n",
    "    \n",
    "    network.init_variables()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        counter = lambda n: tqdm(range(n), desc='Epoch {:>2}/{}'.format(i + 1, epochs), unit='batches')\n",
    "        for (k, X_k, y_k) in batches(data.train, batch_size, counter):\n",
    "            loss = optimizer(X_k, y_k)\n",
    "\n",
    "            if k % batch_step == 0:\n",
    "                (a_train, a_valid) = accuracy()\n",
    "                x_batch.append(len(x_batch) * batch_step)\n",
    "                y_train.append(a_train)\n",
    "                y_valid.append(a_valid)\n",
    "                y_loss.append(loss)\n",
    "\n",
    "        plot_lines('Loss', x_batch,\n",
    "            (y_loss, 'g', 'Loss')\n",
    "        )\n",
    "\n",
    "        plot_lines('Accuracy', x_batch,\n",
    "            (y_train, 'r', 'Training Accuracy'),\n",
    "            (y_valid, 'b', 'Validation Accuracy'),\n",
    "            loc=4\n",
    "        )\n",
    "\n",
    "\n",
    "def load(network, path):\n",
    "    session = network.session\n",
    "    with session.graph.as_default():\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(session, path)\n",
    "\n",
    "\n",
    "def save(network, path):\n",
    "    session = network.session\n",
    "    with session.graph.as_default():\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(session, path)\n",
    "\n",
    "\n",
    "def trained_network():\n",
    "    data = Attributes()\n",
    "    data.train = Normalized(Vectorized(Padded('Train', 'datasets/pickled/train.p', n_class=2400)))\n",
    "    #data.train = Normalized(Vectorized('Train', 'datasets/pickled/train.p'))\n",
    "    (data.train, data.valid) = split(data.train)\n",
    "\n",
    "    parameters = default_parameters()\n",
    "    parameters.inputs.side = data.train.X.shape[1]\n",
    "    parameters.output.classes = data.train.y.breadth\n",
    "\n",
    "    network = Network(mini_inception_architecture, parameters)\n",
    "    train(network, data, parameters)\n",
    "    save(network, 'network.chk')\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network = trained_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    data_test = Normalized(Vectorized('Test', 'datasets/pickled/test.p'))\n",
    "\n",
    "    network = Network(mini_inception_architecture, default_parameters())\n",
    "    load(network, 'network.chk')\n",
    "    \n",
    "    accuracy = Accuracy(network, 50, data_test)\n",
    "    \n",
    "    print('Test performance: %.3f' % round(accuracy()[0], 3))\n",
    "\n",
    "\n",
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "_How did you train your model? (Type of optimizer, batch size, epochs, hyperparameters, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "I experimented with the Adam Optimizer, but after much fiddling with parameters, I coudln't get any especially good results out of it; I also had several instances of optimization getting stuck at local minima, and even some NaN occurrences. So pending a more thorough evaluation of the method, I reverted to gradient descent, which proved reliable and effective enough for my purposes.\n",
    "\n",
    "Hyperparameters, including batch size and number of epochs, were most taken from other Udacity notebooks, notably the Tensor Flow Lab and the Convolutional Networks notebook from the Deep Learning course. With few exceptions (e.g. the number of hidden layers was chosen as 64 rather than the more common 32) I found the parameters specified in those notebooks to be very close to optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "First I implemented a basic system that would go through all the steps of loading and preparing the data, instantitating the network, training it and presenting results. Once this initial version was in place, I went about improving it piece by piece, refining data management, experimenting with different network architectures, and varying parameters. I stopped when it became clear that any further improvement would take more time than I had available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "Take several pictures of traffic signs that you find on the web or around you (at least five), and run them through your classifier on your computer to produce example results. The classifier might not recognize some local signs but it could prove interesting nonetheless.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def load_odd_images():\n",
    "    return Dataset('Odd Images', 'datasets/images/', breadth=43)\n",
    "\n",
    "def display_odd_images():\n",
    "    odd_images = load_odd_images()\n",
    "    display(odd_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __demos__ == True:\n",
    "    display_odd_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "_Choose five candidate images of traffic signs and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult? It would be helpful to plot the images in the notebook._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Some traffic signs in the selected images differ from dataset images in proportions (e.g. border thickness), but otherwise they shouldn't pose a challenge to the trained classifier. For one ligthing is overall much better than in the training set, with sharper constrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Run the predictions here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "\n",
    "class Argmax(object):\n",
    "    def __init__(self, network):\n",
    "        self.inputs = network.inputs\n",
    "        self.session = network.session\n",
    "        with self.session.graph.as_default():\n",
    "            self.argmax = tf.argmax(network.outputs, 1)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.session.run(self.argmax, feed_dict={self.inputs: X})\n",
    "\n",
    "\n",
    "def run_odd_images():\n",
    "    odd_images = Normalized(Vectorized(load_odd_images()))\n",
    "\n",
    "    network = Network(mini_inception_architecture, default_parameters())\n",
    "    load(network, 'network.chk')\n",
    "\n",
    "    predict = Argmax(network)\n",
    "    yp = predict(odd_images.X.data)\n",
    "    \n",
    "    for (k, yp_k) in enumerate(yp):\n",
    "        y_k = odd_images.y.classof(k)\n",
    "        print('Class of entry %d is %d, predicted as %d' % (k, y_k, yp_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_odd_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the dataset?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "As long as traffic signs can be located and extracted from images, it shouldn't matter whether they come from still images or video stream frames. Images in the training dataset aren't exactly high-definition, so blurring and other video camera artifacts shouldn't pose much of a problem either. It does remain to be seen whether the architecture as currently implemented could keep pace with a live image stream, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "class SoftmaxTopK(object):\n",
    "    def __init__(self, network, k=5):\n",
    "        self.inputs = network.inputs\n",
    "        self.session = network.session\n",
    "        with self.session.graph.as_default():\n",
    "            self.outputs = tf.nn.top_k(tf.nn.softmax(network.outputs), k)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        result = self.session.run(self.outputs, feed_dict={self.inputs: X})\n",
    "        return [(k, v) for (k, v) in zip(result.indices, result.values)]\n",
    "\n",
    "\n",
    "def run_top_5():\n",
    "    odd_images = Normalized(Vectorized(load_odd_images()))\n",
    "\n",
    "    network = Network(mini_inception_architecture, default_parameters())\n",
    "    load(network, 'network.chk')\n",
    "\n",
    "    predict = SoftmaxTopK(network)\n",
    "    yp = predict(odd_images.X.data)\n",
    "    \n",
    "    for (k, (indices, values)) in enumerate(yp):\n",
    "        y_k = odd_images.y.classof(k)\n",
    "        yp_k = ', '.join(('(%d: %.4f)' % (k, v)) for (k, v) in zip(indices, values))\n",
    "        print('Class of entry %d is %d, predictions were: %s' % (k, y_k, yp_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_top_5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "*Use the model's softmax probabilities to visualize the **certainty** of its predictions, [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k) could prove helpful here. Which predictions is the model certain of? Uncertain? If the model was incorrect in its initial prediction, does the correct prediction appear in the top k? (k should be 5 at most)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Predictions were fairly reliable for the example images used. The least certain result, the stop sign, was likely due to the image not being perfectly centered, however it was still able to correctly predict the correct label with sufficient certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Because of the way the architecture was implemented, with object-oriented API's that build upon one another, adding new features to the system (in this case, to load and classify images acquired after the network was trained) was fairly straighforward: just a matter of writing a couple more wrappers to compute the desired values, and then running the appropriate callables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
